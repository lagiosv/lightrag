# LightRAG Configuration for Coolify Deployment
# This file is for reference only. Actual values should be set in Coolify Environment Variables

###########################
### Server Configuration
###########################
HOST=0.0.0.0
PORT=9621
WEBUI_TITLE='LightRAG Knowledge Base'

### Directory Configuration
WORKING_DIR=/app/data/rag_storage
INPUT_DIR=/app/data/inputs
TIKTOKEN_CACHE_DIR=/app/data/tiktoken

###########################
### LLM Configuration
###########################
LLM_BINDING=openai
LLM_MODEL=anthropic/claude-sonnet-4.5
LLM_BINDING_HOST=https://openrouter.ai/api/v1
LLM_BINDING_API_KEY=your_openrouter_api_key
MAX_ASYNC=4

### Vision Model for RAG-Anything multimodal processing
VISION_MODEL=openai/gpt-5

###########################
### Embedding Configuration
### CRITICAL: Using 3072 dimensions for maximum quality
###########################
EMBEDDING_BINDING=openai
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIM=3072
EMBEDDING_BINDING_HOST=https://api.openai.com/v1
EMBEDDING_BINDING_API_KEY=your_openai_api_key

###########################
### Storage Configuration
###########################
LIGHTRAG_GRAPH_STORAGE=Neo4JStorage
LIGHTRAG_KV_STORAGE=PGKVStorage
LIGHTRAG_DOC_STATUS_STORAGE=PGDocStatusStorage
LIGHTRAG_VECTOR_STORAGE=PGVectorStorage

###########################
### Neo4j Configuration
###########################
NEO4J_URI=bolt://your-neo4j-container:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password
NEO4J_DATABASE=neo4j
NEO4J_MAX_CONNECTION_POOL_SIZE=100

###########################
### PostgreSQL Configuration (Supabase)
###########################
POSTGRES_HOST=your-supabase-db-container
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_postgres_password
POSTGRES_DATABASE=postgres
POSTGRES_MAX_CONNECTIONS=20

### Vector Index Settings (HNSW for best quality with 3072-dim vectors)
POSTGRES_VECTOR_INDEX_TYPE=HNSW
POSTGRES_HNSW_M=16
POSTGRES_HNSW_EF=200

###########################
### Document Processing
###########################
CHUNK_SIZE=1200
CHUNK_OVERLAP_SIZE=100
ENABLE_LLM_CACHE=true
ENABLE_LLM_CACHE_FOR_EXTRACT=true

###########################
### RAG-Anything Configuration
### These are used for multimodal document processing
###########################
# Automatically uses VISION_MODEL for image processing
# Automatically uses LLM_MODEL for text extraction and summarization
# Multimodal processing enabled by default when RAG-Anything dependencies are installed
